{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.07825672, -0.09973021, -0.0365219 , ...,  0.05358921,\n",
       "          0.07731829, -0.05953887],\n",
       "        [ 0.10232424,  0.00458265, -0.05456071, ..., -0.08395068,\n",
       "          0.07963235, -0.09261419],\n",
       "        [ 0.02274563, -0.04224518, -0.05519225, ...,  0.06423434,\n",
       "          0.01742372, -0.03705605],\n",
       "        ...,\n",
       "        [ 0.08415173, -0.02694921,  0.1104775 , ..., -0.03496844,\n",
       "          0.11977541, -0.09278696],\n",
       "        [ 0.05606542,  0.02197399,  0.10943548, ..., -0.07770881,\n",
       "         -0.06790782,  0.06090263],\n",
       "        [-0.03833635, -0.0801408 ,  0.0412591 , ..., -0.09481721,\n",
       "         -0.02753908,  0.0483412 ]]),\n",
       " array([[ 0.05408523,  0.02094522, -0.09604994, ..., -0.06459794,\n",
       "          0.08963507, -0.0357565 ],\n",
       "        [-0.04857243,  0.03833608, -0.03684097, ...,  0.02233409,\n",
       "          0.05385499,  0.0801044 ],\n",
       "        [ 0.09904466,  0.0411483 ,  0.10960868, ...,  0.11355427,\n",
       "         -0.09996735,  0.08570318],\n",
       "        ...,\n",
       "        [ 0.07813201,  0.04091359,  0.01456675, ...,  0.03752645,\n",
       "         -0.07012375,  0.11616883],\n",
       "        [ 0.07622294, -0.07177314,  0.0866136 , ..., -0.09354423,\n",
       "         -0.03800142, -0.09697883],\n",
       "        [ 0.03676035,  0.08146804,  0.03856923, ..., -0.08753476,\n",
       "          0.11580331, -0.09532616]])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Current function value: 1.104335\n",
      "         Iterations: 10\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "0.8444\n",
      "Predicciones: \n",
      " [0 0 0 ... 9 9 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danit\\anaconda3\\envs\\entornoIA2425\\lib\\site-packages\\scipy\\optimize\\_optimize.py:1659: OptimizeWarning: Maximum number of iterations has been exceeded.\n",
      "  res = _minimize_cg(f, x0, args, fprime, callback=callback, c1=c1, c2=c2,\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.optimize as opt\n",
    "import sklearn.metrics\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def holdout(X, y, percentage=0.6):\n",
    "  X_training = X.sample(round(percentage*len(X))) \n",
    "  y_training = y.iloc[X_training.index]\n",
    "  X_test = X.iloc[~X.index.isin(X_training.index)]\n",
    "  y_test = y.iloc[~X.index.isin(X_training.index)]\n",
    "\n",
    "  X_training = X_training.reset_index(drop=True)\n",
    "  y_training = y_training.reset_index(drop=True)\n",
    "  X_test = X_test.reset_index(drop=True)\n",
    "  y_test = y_test.reset_index(drop=True)\n",
    "  \n",
    "  return X_training, y_training, X_test, y_test\n",
    "\n",
    "def normalize(X):\n",
    "    return (X - X.mean()) / X.std()\n",
    "\n",
    "def forward(thetas, X):\n",
    "    activations = []\n",
    "    a = np.hstack((1, X))\n",
    "    activations.append(a)\n",
    "    \n",
    "    for i in range(len(thetas)):\n",
    "        z = np.dot(thetas[i], a)\n",
    "        a = sigmoid(z)\n",
    "        if i < len(thetas) - 1:\n",
    "            a = np.hstack((1, a))\n",
    "        activations.append(a)\n",
    "    \n",
    "    h = activations[-1]\n",
    "    \n",
    "    return activations, h\n",
    "\n",
    "def nnCostFunction(nn_params, layer_sizes, X, y):\n",
    "    thetas = []\n",
    "    start = 0\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        end = start + (layer_sizes[i + 1] * (layer_sizes[i] + 1))\n",
    "        theta = np.reshape(nn_params[start:end], (layer_sizes[i + 1], layer_sizes[i] + 1), order='F')\n",
    "        thetas.append(theta)\n",
    "        start = end\n",
    "\n",
    "    m = len(y)\n",
    "    y_d = pd.get_dummies(y.flatten())\n",
    "    \n",
    "    suma = 0\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        activations, h = forward(thetas, X[i])\n",
    "        temp1 = y_d.iloc[i] * np.log(h)\n",
    "        temp2 = (1 - y_d.iloc[i]) * np.log(1 - h)\n",
    "        temp3 = np.sum(temp1 + temp2)\n",
    "        suma = suma + temp3\n",
    "\n",
    "    J = (np.sum(suma) / (-m))\n",
    "    return J\n",
    "\n",
    "def nnGradFunction(nn_params, layer_sizes, X, y):\n",
    "    thetas = []\n",
    "    start = 0\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        end = start + (layer_sizes[i] + 1) * layer_sizes[i + 1]\n",
    "        theta = np.reshape(nn_params[start:end], (layer_sizes[i + 1], layer_sizes[i] + 1), order='F')\n",
    "        thetas.append(theta)\n",
    "        start = end\n",
    "\n",
    "    m = len(y)\n",
    "    y_d = pd.get_dummies(y.flatten())\n",
    "    deltas = [np.zeros(theta.shape) for theta in thetas]\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        a = [np.hstack((1, X[i]))]\n",
    "        for theta in thetas:\n",
    "            a.append(np.hstack((1, sigmoid(a[-1] @ theta.T))))\n",
    "        a[-1] = a[-1][1:]\n",
    "\n",
    "        d = [a[-1] - y_d.iloc[i]]\n",
    "        for j in range(len(thetas) - 1, 0, -1):\n",
    "            d.insert(0, np.multiply(thetas[j].T @ d[0], np.multiply(a[j], 1 - a[j]))[1:])\n",
    "\n",
    "        # Paso 3.3: Cálculo de las derivadas ajustando las dimensiones de los errores y las activaciones de cada capa correctamente\n",
    "        for j in range(len(deltas)):\n",
    "            deltas[j] += np.reshape(d[j], (layer_sizes[j + 1], 1)) @ np.reshape(a[j], (1, layer_sizes[j] + 1))\n",
    "\n",
    "    deltas = [delta / m for delta in deltas]\n",
    "    gradiente = np.hstack([delta.ravel(order='F') for delta in deltas])\n",
    "    return gradiente\n",
    "\n",
    "def training(initial_thetas, X_train, y_train, layer_sizes):\n",
    "    maxiter = 10\n",
    "\n",
    "    nn_initial_params = np.hstack([theta.ravel(order='F') for theta in initial_thetas])\n",
    "\n",
    "    nn_params = opt.fmin_cg(maxiter=maxiter, f=nnCostFunction, x0=nn_initial_params, fprime=nnGradFunction,\n",
    "                            args=(layer_sizes, X_train, y_train.flatten()), gtol=0.005)\n",
    "\n",
    "    thetas = []\n",
    "    start = 0\n",
    "    for i in range(len(layer_sizes) - 1):\n",
    "        end = start + (layer_sizes[i + 1] * (layer_sizes[i] + 1))\n",
    "        theta = np.reshape(nn_params[start:end], (layer_sizes[i + 1], layer_sizes[i] + 1), order='F')\n",
    "        thetas.append(theta)\n",
    "        start = end\n",
    "\n",
    "    return thetas\n",
    "\n",
    "def thetasInicial(nlayers, epsilon=0.12):\n",
    "    thetas = []\n",
    "    for i in range(1, len(nlayers)):\n",
    "        theta = np.random.rand(nlayers[i], nlayers[i - 1] + 1) * 2 * epsilon - epsilon\n",
    "        thetas.append(theta)\n",
    "    return thetas\n",
    "\n",
    "data = sio.loadmat('datasets/ex4data1.mat')\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "\n",
    "y = y % 10\n",
    "\n",
    "# Definir el número de neuronas por capa\n",
    "nlayer = [400, 200, 10]\n",
    "thetas = thetasInicial(nlayer)\n",
    "display(thetas)\n",
    "# Entrenamiento de la red neuronal\n",
    "trained_thetas = training(thetas, X, y, nlayer)\n",
    "\n",
    "def predict(thetas, X):\n",
    "    ones = np.ones((len(X), 1))\n",
    "    a = np.hstack((ones, X))\n",
    "    for theta in thetas[:-1]:\n",
    "        a = np.hstack((ones, sigmoid(a @ theta.T)))\n",
    "    h = sigmoid(a @ thetas[-1].T)  # La hipótesis o predicción\n",
    "    \n",
    "    # La predicción será el índice de la clase con mayor probabilidad\n",
    "    pred = np.argmax(h, axis=1)\n",
    "    return pred\n",
    "\n",
    "# Realizar predicciones\n",
    "predictions = predict(trained_thetas, X)\n",
    "print(sklearn.metrics.accuracy_score(y, predictions))\n",
    "\n",
    "print(\"Predicciones: \\n\", predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entornoIA2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
