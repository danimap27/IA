{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-eNq8xptvP2"
      },
      "source": [
        "# INTELIGENCIA ARTIFICIAL: EB Ejercicios Tema 4: REGRESIÓN LOGÍSTICA \n",
        "## EJERCICIO: ¿Cómo resolver un problema multiclase?\n",
        "**Implementar** una regresión logística para reconocer números escritos a mano del 1 al 10. Use como método de evaluación holdout, donde el conjunto de entrenamiento está formado por el 70% de las primeras filas del conjunto de datos, y el conjunto de test por el resto.\n",
        "\n",
        "Para ello, tenemos un conjunto de datos formado por 5000 ejemplos de dígitos escritos a mano en **ex4data1.mat**. La extensión .mat indica que contiene datos salvados en formato matriz Octave/Matlab nativo en vez de en formato texto. Una vez cargado el fichero .mat, tendrás en memoria la variable **X** que contiene la matriz de atributos, y el vector **y** que contiene las etiquetas.\n",
        "\n",
        "Después de un preprocesado de las imágenes formadas por los dígitos escritos a mano, cada imagen se codifica como un vector de 400 elementos, donde cada elemento es un número decimal que representa la intensidad de gris en una posición determinada. Las etiquetas son 1, 2, 3, 4, 5, 6, 7, 8, 9, 0 donde la etiqueta 0 representa el dígito 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwH0TCg8u0KW"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import scipy.optimize as op\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDYUZD8HuJ4s"
      },
      "source": [
        "# A) EJERCICIO BASE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBeOzNH1uOP6"
      },
      "source": [
        "## 1) Cargar los datos de entrada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kC-ye1DTuphi",
        "outputId": "c40754d1-9b3e-4330-d554-1474956acc1c"
      },
      "source": [
        "print(\"Cargando los datos ...\\n\")\n",
        "data = sio.loadmat(\"ex4data1.mat\") # dict type\n",
        "\n",
        "X = pd.DataFrame(data['X'])\n",
        "y = pd.DataFrame(data['y'])\n",
        "m = X.shape[0]\n",
        "\n",
        "print(\"El tamaño de X es: \", X.shape)\n",
        "print(\"La longitud del vector y es: \", len(y))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cargando los datos ...\n",
            "\n",
            "El tamaño de X es:  (5000, 400)\n",
            "La longitud del vector y es:  5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOlhRE4gUdbK"
      },
      "source": [
        "## 2) Hipótesis y función coste\n",
        "En regresión logística el modelo viene definido por: \n",
        "\\begin{equation}\n",
        "h_{\\theta}(X) = g(X\\theta)\n",
        "\\end{equation}\n",
        "\n",
        "siendo  \n",
        "\n",
        "\\begin{equation}\n",
        "g(z) = \\frac{1}{1+e^{-z}}\n",
        "\\end{equation}\n",
        "\n",
        "El objetivo de la regresión logística es minimizar el coste de la función:\n",
        "\n",
        "\\begin{equation}\n",
        "J(\\theta)=\\frac{-1}{m}\\sum_{i=1}^{m} (y^i \\cdot log(h_{\\theta}(x^i))+(1-y^i)\\cdot log(1-h_{\\theta}(x^i)))\n",
        "\\end{equation}\n",
        "\\begin{equation}\n",
        "= \n",
        "\\frac{-1}{m}\\sum (y \\cdot log(h_{\\theta}(X))+(1-y)\\cdot log(1-h_{\\theta}(X)))\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aCQvhwrZuHRK"
      },
      "source": [
        "def sigmoid(z):\n",
        "    g = 1 / (1+np.exp(-z)) \n",
        "\n",
        "    return g\n",
        "\n",
        "def costFunction(theta, X, y):\n",
        "    m = len(y)\n",
        "    h = sigmoid(np.dot(X, theta))\n",
        "    J = -(1 / m) * np.sum((y * np.log(h)) + ((1 - y) * np.log(1 - h)))\n",
        "\n",
        "    return J"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AatQET0NbWZX"
      },
      "source": [
        "#### 2.1) Añadir $x_0$\n",
        "x0 se añade como primera columna a X con todos sus elementos a 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4mII1oib22R"
      },
      "source": [
        "X.insert(0, 'ones', 1) # Se crea una nueva columna 'ones' en la primera columna (primer parámetro:0) con todos sus valores a 1 (tercer parámetro:1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4YTH92Tbfyz"
      },
      "source": [
        "#### 2.2) Inicializar $\\theta$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdO-u-2nbD-w"
      },
      "source": [
        "num_atributos = X.shape[1] # Si esta operación la hacemos antes de añadir la columna de 1 a X, debemos poner X.shape[1]+1\n",
        "initial_theta = np.zeros((num_atributos,1), dtype=np.float64)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt8n4VVdCjU2"
      },
      "source": [
        "## 3) Descenso del Gradiente para optimización\n",
        "Con el objeto de usar la función avanzada de optimización de python fmin_cg, se va a usar la función gradientFunction_optimization que devuelve el valor del gradiente formado por las derivadas parciales. Las derivadas parciales se calculan como:\n",
        "\\begin{equation}\n",
        "\\frac{\\partial J(\\theta)}{\\partial \\theta_j}=\\frac{1}{m}\\sum_{i=1}^{m} (h_{\\theta}(x^i)-y^i)\\cdot x_j^i\n",
        "\\end{equation}\n",
        "Recordar que para que la programación sea eficiente el gradiente se debe vectorizar.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ee-sEnx399lk"
      },
      "source": [
        "def gradientFunction_optimization(theta, X, y):\n",
        "    m = len(y)\n",
        "    \n",
        "    h = sigmoid(np.dot(X, theta))\n",
        "    grad = (1/m) * (np.dot(X.T,(h-y))) # Recuerde: grad debería tener las mismas dimensiones que theta\n",
        "\n",
        "    return grad"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HgcJ59Q-DuY"
      },
      "source": [
        "### 3.1) Función que transforma la salida (multiclase) para poder usarse en problemas de clasificación binaria.\n",
        "Para ello hay que implementar una función que reciba como parámetros: la salida ($y$) y el valor de la clase actual (de 1 a 10 en este caso) que se esté usando en el problema de clasificación binaria. La salida de la función tendrá tantas filas como tuviese $y$ con valor 1 cuando la clase que se pasa por parámetro coincida con el valor de $y$ en esa fila y con 0 en caso contrario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQQoVWa5-kBp"
      },
      "source": [
        "# COMPLETAR\n",
        "# OPCION 1\n",
        "def y_change(y, cl):\n",
        "  return ...  # One-hot enconding de y seleccionando la columna de la clase cl\n",
        "\n",
        "# OPCION 2\n",
        "def y_change1(y, cl):\n",
        "    y_pr=[] # Lista vacía para ir añadiendo 0 o 1 según si el valor de la fila de y es cl o no\n",
        "    for i in range(0, len(y)): # Recorro todas las filas de y\n",
        "        if y[0][i] == cl: # y tiene una columna que se llama 0 y las filas las recorremos con i\n",
        "            y_pr.append(1) # Añado 1 a la lista si el valor de la fila i es cl\n",
        "        else:\n",
        "            y_pr.append(0) # Añado 0 a la lista si el valor de la fila i no es cl\n",
        "    y_new = pd.DataFrame({'label':y_pr})\n",
        "    return y_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uNGgptUAJ5z"
      },
      "source": [
        "### 3.2) Función para entrenar problemas de clasificación multiclase\n",
        "Implementar una función llamada training que sea la encargada de realizar el entrenamiento del método. Para ello, esta función recibirá el número de clases, los parámetros theta iniciales y el conjunto de entrenamiento (X_train,y_train), y devolverá los parámetros theta que definen el modelo aprendido. Las dimensiones de estos son num_class x (n+1), donde n es el número de atributos de la matriz X.\n",
        "\n",
        "Dado que se trata de un problema de clasificación multiclase, habría que reducir el problema a problemas de clasificación binaria que es lo que sabemos resolver. En concreto, a 10 problemas de clasificación binaria ya que tenemos 10 clases. En el entrenamiento de cada regresión logística hay que pasarle el conjunto de entrenamiento adecuado. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhQYQelSbj4i"
      },
      "source": [
        "# COMPLETAR\n",
        "def training(initial_theta, X_train, y_train, num_clases):\n",
        "  all_theta = [] # Lista vacía para incluir las theta óptimas de cada clase\n",
        "  all_cost = [] # Lista vacía para incluir el coste final de cada clase\n",
        "  all_class = [] # Lista vacía para añadir las clases\n",
        "\n",
        "  for current_class in range(1, num_clases+1): # Vamos a aplicar el algoritmo de optimización a cada clase (desde 1 hasta 10 (se pone +1 para que se incluya el 10 en el for))\n",
        "      res_optimization = op.fmin_cg(maxiter=50, f=..., x0=...., \n",
        "                                    fprime=....,\n",
        "                             args=(X, y_change(y, current_class).to_numpy().flatten()), \n",
        "                             full_output = True) # Indicando full_output=True la salida del algoritmo de optimización\n",
        "                                # será en la posición [0] los theta óptimos y en la posición [1] el coste alcanzado por esos theta optimos\n",
        "\n",
        "      all_theta.append(res_optimization[0]) # Theta óptimos del algoritmo de optimización\n",
        "      all_cost.append(res_optimization[1]) # Coste del algoritmo de optimización\n",
        "      all_class.append(current_class) # Clase actual\n",
        "    \n",
        "  df_opt = pd.DataFrame({'class':all_class, 'theta':all_theta, 'cost':all_cost}) # Creamos dataframe que devolverá la función\n",
        "  \n",
        "  return df_opt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IE08cLwPKPUF"
      },
      "source": [
        "## 4) Predecir en problemas multiclase\n",
        "Tenga en cuenta que la predicción es la predicción que tiene una mayor probabilidad de entre todas las predicciones obtenidas por los 10 modelos. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ7S9rmPDsAI"
      },
      "source": [
        "# COMPLETAR\n",
        "def predict(res_optimization, X):\n",
        "  m = len(X)\n",
        "  all_instances = [] # Lista vacía para incluir las instancias/filas de X\n",
        "  all_predictions = [] # Lista vacía para incluir las predicciones\n",
        "\n",
        "  for i in range(0, len(X)): # Para cada fila de X\n",
        "    all_h = [] # Lista vacía para añadir las h de la fila i (tamaño de all_h: num_classes en este caso 9)\n",
        "  \n",
        "    for current_class in res_optimization['class']: # Para los theta optimos de cada clase\n",
        "      h = .... \n",
        "      all_h.append(h) # Añado cada h a la lista all_h\n",
        "    \n",
        "    pred = np.argmax(all_h)+1 # ¡¡IMPORTANTE!! Busco la mejor predicción. La función devuelve el índice de la mejor predicción (predicciones son de 1 a 10 y no de 0 a 9)\n",
        "    all_predictions.append(pred) # Añado la mejor a la lista de predicciones finales\n",
        "    all_instances.append(i) # Añado la instancia/fila a la lista\n",
        "  \n",
        "  return pd.DataFrame({'instance':all_instances, 'prediction':all_predictions})\n",
        "\n",
        "def accuracy_model (y_real, y_predictions):\n",
        "  return np.mean(y_predictions['prediction']==y_real[0]) # [0] es porque la columna del dataframe y_real se llama 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhl9oDduwBxM"
      },
      "source": [
        "# B) EVALUACIÓN USANDO HOLDOUT\n",
        "Una vez tenemos todas las funciones necesarias, vamos a unir todas las piezas para implementar la función principal. El programa principal consta de las siguientes partes:\n",
        "\n",
        "\n",
        "1. Inicializar los parámetros necesarios.\n",
        "2. Dividir el dataset en 70% para entrenamiento y 30% para test usando la función holdout suministrada en EB Ejercicios T3.\n",
        "3. Obtener todos los modelos y los valores del coste J a través de las iteraciones de todos los modelos usando la función training. \n",
        "4. Predecir el conjunto de training y calcular el error.\n",
        "5. Predecir el conjunto de test y calcular el error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rrZv5m6ENYA"
      },
      "source": [
        "# OPCION 2\n",
        "def holdout_opcion2(X, y, percentage=0.6):\n",
        "  X_training = X.sample(round(percentage*len(X))) # Selecciona aleatoriamente el numero de filas indicado\n",
        "  y_training = y.iloc[X_training.index] # Selecciona las filas del X_training\n",
        "  X_test = X.iloc[~X.index.isin(X_training.index)] # ~ significa NOT\n",
        "  y_test = y.iloc[~X.index.isin(X_training.index)] # ~ significa NOT\n",
        "\n",
        "  print(\"El tamaño del training debe ser: \", round(percentage*len(X)), \" - Comprobación: tamaño X_training es \", len(X_training), \" y tamaño y_training es\", len(y_training))\n",
        "  print(\"El tamaño del test debe ser: \", len(X)-round(percentage*len(X)), \" - Comprobación: tamaño X_test es \", len(X_test), \" y tamaño y_test es\", len(y_test))\n",
        "\n",
        "  # Reseteamos los índices de todos los conjuntos\n",
        "  X_training = X_training.reset_index(drop=True)\n",
        "  y_training = y_training.reset_index(drop=True)\n",
        "  X_test = X_test.reset_index(drop=True)\n",
        "  y_test = y_test.reset_index(drop=True)\n",
        "  \n",
        "  return X_training, y_training, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WWELCoIaa5o"
      },
      "source": [
        "# COMPLETAR\n",
        "# Paso 1:\n",
        "num_classes = 10\n",
        "initial_theta = np.zeros((X.shape[1],1))\n",
        "# Columna de 1s en la primera posición de X está ya hecho --> comprobar\n",
        "\n",
        "# Paso 2: HOLDOUT 70-30\n",
        "X_training, y_training, X_test, y_test = holdout_opcion2(X, y, 0.7)\n",
        "\n",
        "# Paso 3: ENTRENAMIENTO\n",
        "res_optimization_training = training(initial_theta, ..., ..., num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-4zuNZeadDS"
      },
      "source": [
        "# COMPLETAR\n",
        "# Paso 4\n",
        "res_prediction_training = ... # PREDICCIÓN DEL TRAINING\n",
        "accuracy_training = ... # ACCURACY DE LA PREDICCIÓN DEL TRAINING\n",
        "print(\"Training accuracy: \", acc_training)\n",
        "print(\"Training accuracy sklearn:\", metrics.accuracy_score(y_training,res_prediction_training['prediction']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqfJFdrkaezn"
      },
      "source": [
        "# COMPLETAR\n",
        "# Paso 5\n",
        "res_prediction_test = .... # PREDICCIÓN DEL TEST\n",
        "accuracy_test = ... # ACCURACY DE LA PREDICCIÓN DEL TEST\n",
        "print(\"Test accuracy: \", accuracy_test)\n",
        "print(\"Test accuracy sklearn:\", metrics.accuracy_score(y_test, res_prediction_test['prediction']))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}