{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlYT5sseBv8P"
   },
   "source": [
    "# INTELIGENCIA ARTIFICIAL: EB Ejercicios Tema 3: REGRESIÓN LINEAL \n",
    "## EJERCICIO: ¿Cómo evaluar modelos de machine learning?\n",
    "**Evaluar** el modelo de regresión lineal obtenido en la EPD 2.1 para predecir los beneficios de un restaurante según la población de la ciudad. Use diferentes métodos de evaluación y compare los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIdDs76SCwhC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgHF5szVxp6X"
   },
   "outputs": [],
   "source": [
    "# Para Ejercicio de Evaluación usando Holdout\n",
    "from random import randrange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y8c_96kaO_Me"
   },
   "outputs": [],
   "source": [
    "# Para Ejercicio de Evaluación usando Cross Validation\n",
    "from random import randrange\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XuTPohgbvfNx"
   },
   "source": [
    "## A) EJERCICIO BASE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ehPrbDKB004"
   },
   "source": [
    "### 1) Cargar los datos de entrada\n",
    "Los datos están almacenados en el fichero ex1data1.txt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BFRPFABB3v9"
   },
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    # Reading file with data\n",
    "    print('Loading Data ...', file_name)\n",
    "    file = pd.read_csv(file_name, names=[\"poblacion\",\"beneficio\"])\n",
    "    X = pd.DataFrame({'poblacion': file['poblacion']})\n",
    "    y = pd.DataFrame({'beneficio': file['beneficio']})\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SfbVq9nCogW",
    "outputId": "ec8e027c-7de8-4759-ac98-a7ee86f937d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data ... ex1data1.txt\n"
     ]
    }
   ],
   "source": [
    "X, y = read_file('ex1data1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WDVle__DF5P"
   },
   "source": [
    "#### 1.1) Visualizar los datos\n",
    "Visualizar las dimensiones de la matriz de atributos, del vector clase y las primeras 5 filas de los atributos junto a su clase. \n",
    "En el caso de la regresión lineal univariable, representar en una gráfica el atributo de entrada y la clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-3moWvoJDJn2"
   },
   "outputs": [],
   "source": [
    "def plotData(X, y):\n",
    "    plt.scatter(X,y, marker = \"x\", c = \"red\")\n",
    "    plt.xlabel(\"Population of City in 10,000\")\n",
    "    plt.ylabel(\"Profit in $10,000\")\n",
    "    plt.xticks(np.arange(5, 26, 5), rotation=45) \n",
    "    plt.yticks(np.arange(-5, 26, 5), rotation=45)\n",
    "    plt.xlim(5,25) # Estamos limitando el eje x. Si los datos cambian, probablemente habrá que modificar estos valores\n",
    "    plt.ylim(-5,25) # Estamos limitando el eje y. Si los datos cambian, probablemente habrá que modificar estos valores\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "x0GvkO4BDhVw",
    "outputId": "329c2256-676a-4071-cc15-60ed43cf2598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño de X es:  97  filas y  1  columna(s)  (97, 1)\n",
      "La longitud del vector y es:  97 (97, 1)\n",
      "Las 5 primeras filas de los datos son: [atributo entrada X1 | clase y]\n",
      "\t 6.1101  |  17.592\n",
      "\t 5.5277  |  9.1302\n",
      "\t 8.5186  |  13.662\n",
      "\t 7.0032  |  11.854000000000001\n",
      "\t 5.8598  |  6.8233\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEQCAYAAABBQVgLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxdZX3v8c83kRCkkgRCQG5BtAoILURPJIJ4A1oRcECrXrQOTDXUNjknoLeOkKPcFhyakIDDxTqPUGsrWqfXVbhQhEACMSCKcO0Q5sEkFMuY87t/PGux197Z89njOd/367Ve56y11177ORuyfuuZfo8iAjMzs3pm9LsAZmY2+BwszMysIQcLMzNryMHCzMwacrAwM7OGHCzMzKwhBwszM2uob8FCkvr12WZm1pq+BAtJi4Ej+/HZZmbWuqf1+gMlvRJYA7y1jfcuBZYC7LrrriMHHXRQh0tnZja1bdiw4YGI2LPV96mX6T4kHQVcArwtIi6X9HsR8bCkXSLiEUkzImKimWstWrQo1q9f390Cm5lNMZI2RMSiVt/X65rFocDVwIOSngWcJ+khYA9JH4iI2yQpnLDKzAZRBBS7Wyv3p7Ce9FlIeq6kg4FvAz8D3kUKGtcCnwduAC6S9AwHCjMbSOPjcOaZKUBA+nnmmen4NND1moWkVwN/A2wFbgW+CGwHboyIi7Nz7gKeBzzW7fKYmbUsArZuhTVr0v7q1SlQrFkDY2PToobR1WAh6Ujg48CfRsSNkj4DvDkilkvauXDqEuA5wNOBx7tZJjOzlkkpQEAKEHnQGBtLx6d4oIDeNEN9NCJuzH4/G3iWpFkR8RiApNOBvwL+MiK29qA8ZmatKwaM3DQJFND9YLGO1E+BpJnAzsC+wJzs2HOAQ4CTIuIXXS6LmVn78j6KomIfxhTX1WAREdsj4qFsV6R+i99GxP2S3gacAYxHxK+6WQ4zs0nJA0XeRzExkX6uWTNtAkbPhs5GxJPAw5I2SzoPOBY4tRBMzMwGkwRz55b3UeRNUnPnToumqJ5NystyQe0E/DL7+fKIuK3d63lSnpn13BSYZzHwk/Ky+ROPSzoXuH4ygcLMrC8qA8OQBYrJ6HluKOBLnnhnZjZcep511oHCbIqr/Cfuf/JTghc/MrPOmeYpMaYyBwsz64xiSow8YOTDTbdudQ1jyPWjz8LMpiKnxJjSerqeRSd56KzZgIqAGYVGi4kJB4oB0u7QWTdDmVnnTPOUGFOZg4WZdYZTYkxp7rMws87odkqMKTB7epi5z8LMOqsbN/Xx8TSiKg9CeS1m7lwPy22R+yzMbDB0OiWGh+QOBDdDmdlg85DcgeBmKDMbDh6S2xFuhjKzqavekNwhfeAdNm6GMrPBVuyjWLw4bZD280Axb547urvMNQszG2z5kNzR0RQo1q5Nx0dHYd26tO+O7q5zzcLMBt/4eCkYSKVObnBHd4+4g9vMhos7uifFHdxmNvU591TfOFiY2XBw7qm+cp+FmQ2HbueesrrcZ2Fmw8UJBSfFfRZmNj10OveUNaUvwULSvpJmSdo123fQMjMbYD2/SUt6FfAD4CLgC5IOjIgJBwwzs8HVsxu0kn2B84FlwNnAdcAVkg5pJmBIWippvaT1999/fw9KbWZm0MNgEakn/S7gGuA24L6I+AQpePxY0gERMdHgGhdHxKKIWLTnnnt2v9BmZgb0KFhIeq6kFwFzgTnAW7PgQUSsAdYAH5A0W3JvlZnZoOn6PAtJrwb+BtgC3AR8DVgraWZEnJeddinwfuCxGNaxvGZmU1hXg4WkI4GPA38aETdKuhg4HDgSuFbSTOCbwFHACKnmsaWbZTIzs9b1ohnqoxFxY/b7B4EXRMRdwNHAc4CzgOXAqRHhQGFmNoC63Qy1DrgZIKtF7AzsI+mZEfEbSR8G7gR2jYhtXS6LmZm1qas1i4jYHhEPZbsCtgK/jYi7Jb0N+ACwkwOFmdlg61kiwYh4EnhY0mZJ5wHHAqdExCO9KoOZmbWnZ8EiGxK7E/DS7OfLI+K2Xn2+mZm1r5c1iwAel3QucL0DhZnZ8OjHehZf8lwKM+sLpzdvW8+T9zlQmFlfjI+Xr6iXr7w3Pt7PUg2N6ZvptTJmOYaZTV0RsHVr+RKs+RKtW7f6338TpueyquPj6X+QfGnG/H+cuXP9lGE2FRWXYF2zJm1QvkSr1TX9ahZ+wjCbnooBI+dA0bTpFyzy/2HGxlKAmDEj/fQThtnUlj8YFhX7MKyu6RcswE8YZt00iP2BxRaEsTGYmCg9MDpgNGV6Bgs/YZh1x6COOJJSn2SxBSFvYZg71w+KTZh+HdyVTxirV5f2wTUMs3YV+wOh/N/W2Fj/5zSMj5eXIQ8Y/vfelOkXLGo9YYCfMMwmYxhGHFWWYRDKNCQ0rHPkFi1aFOvXr2//Ap7JadYdEWngSG5iwv+2BoikDRGxqNX3Tc8+C/AThlk3uD9wypq+wcLMOssjjqa06ddnYWbd4f7AKW369lmYWXe4P3Cguc/CzAaD+wOnJAcLMzNryMHCrNIgpqsw6zMHC7OiQU1XYdZnDhZmOaevN6vJQ2fNcsOQrsKsTzx01qyS01XYFNaVobOS5kg6X9KvJP1W0oOSfpkdm9t+cc0GlNNVmFXVqM/iUmALcHRE7B4RewDHZMcubfdDJe3S7nvNGmp3NJPTVZjV1KjPYv+I+GjxQETcA3xU0mntfKCkVwKHSrowIh5t5xpmNY2Pp87ovI8hDwBz5zYe0eR0FWY1NQoW/y7pr4AvRcS9AJL2Ak4BNrf6YZKOB84HxioDhSRFgw4USUuBpQD77bdfqx9vU10nFt/xAjlmVdXt4JY0D3gfcCKwV3b4HuAy4KMR8dumP0g6GPhn4LyIuFjSHsB8YFZE3JSd0zBg5NzBbVUVm5JyHs1k9pR2O7h7NhpK0ghwOnADcAfwHuBBYHfgVxGxvJXrOVhYTR7NZFZT1xIJSnqlpE9LuizbPi3puBYKdgBARGwAvgYcAnwS+BbwZuA04PmSXtpq4c124NFMZl1Rt89C0gXAAcCXSbUBgN8HRiUdHxFjDd7/auBSSZdFxJsj4mpJTwBXRsQ/ZqdtlnQH8MSk/hKzytFMxT4LcFOU2SQ06uA+ISIOqDwo6RLg10DNYCFpV2AZsAI4UtLXI+JPI+K64tBZSW8g1TbubucPmNK8LkBrPJrJrGsadXBvAk6PiOsrjh8OfC4i/qjuxaV9gIeA2cBngMci4q2F108mBZRTI+LmVgo+5fssJjMEdLpzkDWrqVt9FqcAF0m6RdKPs+2XwNrstboi4q6IeDgiHgDOAGZL+mpW4OcDuwIntRoopjwntGtOrcl3XnzHrOPqNkNFxA3AYkl7A/8tO3xnNjGvJRHxoKQzgI9LuhUQsCQi3PxUyQntGnPNy6ynmhkNNQdYUtzazQuV1TA2AXOANzhQ1FEMGDkHisQ1L7Oea5RI8B2keRFHA0/PtmOADdlrLckm+Z0AHJtPxLMaPAS0tjyQ5nmbZswoHwHlgGrWcY06uG8FFkfE1orj84B11UZKNfxAaXYnckJN6Q7uekNAfUMs8eQ7s5Z1q4NbQLVoMpG91jInD2xCrSGgY2MeAppzzcuspxrNs/hr4AZJP6aUOHA/4BXAud0s2LTnhHa1efKdWc81Gg31JUmXAa+kNBrqCuD9EbGly2UzDwGtzpPvzHrOy6ra8PLkO7OWdS2RYI0P+z+SfpDlfjLrD9e8zHqmUZ9FLe8Angm8uINlsWpaeXr2k3b/+Lu3Ka7pmoWk3SXtDk+l8dgQEZ/sXtGmqWKz4Pg4rFhROpZ37FaboTw+Xj4aqN651ln+7m0aaDQpbz9J35R0P7AOuE7Sfdmx/XtRwIFUKyfRZBVvOhGwZQusXQtHHFF/lrJnNPePv3ubLiKi5gZcA5wEzCwcm0latOjaeu/t9jYyMhJ9sXJlxNhYxMRE2p+YSPsrV07uuvl1oHT90dE8bJS24mfXen+jc62z/N3bEAHWRxv33EbB4rZ2XuvF1pdgUe2GXrnfqevnW2XAqPcZExPNn2ud5e/ehkS7waJRn8UGSZ+StFjSPtm2WNKngBu7U9cZYN3OSVQteWClWrOUwzOa+8bfvU0H9SIJMAt4F/BD4KZs+wHwF8DO7USnTm19a4aK6N5TZLWaRV67qFeL6XaNx2rzd29DhjZrFo1mcD8OfDrbDGo/RU62ZpFft1hTOeIIWLeudE6tWcqe0dw//u5tmmh7BrekcyLiIx0uT9P6MoO72g29k9lgqy3os2IFzJtXGoYZnmcxkPzd25BodwZ3u5PyAP4M6Fuw6ItuP0VWSx54wQU71iLqla/evnWPv3ub4hqtZ/FQrZeAXSJiMsFmUvqaG8pPkWY2pLpVs9gKvCgi7q3ygZurnD89+CnSzKaZRkNnvww8q8ZrX+9wWczMbEA1Gg31oTqvvbfzxTEzs0HUcoryLF/UQd0ojFlLKvvbPAnOrGsaBgtJ50s6OPv9DcBVwCWS/rrbhTOryZlezXqqmZrFcRFxS/b7mcCxwAsBL3xk/RHO9GrWa3X7LCStBPaSdA6wC/AHpCy0AuZkx6+IiCu7XlKzXHF+y5o1aYPO5egysx00nMEt6RLgYWA34DcR8V5Js4DLI+Ilky6ApGhjGrnX4DYiUjLH3MSEA4VZA91cg/s0YD0pmWA+Omo/4LxWPwwgy1q7RNKLACIipOb+hUtaKmm9pPX3339/Ox9vU4UzvZr1VMNgERG/i4hPR8TnIuKJ7NjtEfG9Vj9M0vHAV4G3Ah+Q9Lnsek0FjIi4OCIWRcSiPffcs9WPt6miMkfXxEQpbbwDhllX9Cxdh6SZwMnARyLiK5J2A34g6VsR8cY8YLTTJLUDp+OY2pzp1azn2s4629aHSe8F7oqIrxSOXQXcEhFntHKtmn0W1TK3nnlmuol4WOXU0sxDgR8czMp0s89iUiQdUNi9E3ivpP0Kx14P7CHpkEl/mIdUTi+NcnR5LoZZxzTVDCVpT+CdwP7F90TEaQ3e92rgUkmXRcSbI+Krkg4Erpb0koj4j4h4QNKTwK5t/xWlD/SQSkuKDw6w49ojrmGYtaSpZihJPyPN3N4AbM+PR8Q/1HnPrsA/AN8GjiQtw/qW7LVzgdcCnwLmkzq8XxUR/9pswesOnfWQSoPymmXODw42zbXbDNVssNgYEQvbKNQ+wEPAbOAzwBOFgPF6YG9gBLggIm5u5do1g4VvEFbkBwezMt3us/iepBNavXhE3BURD0fEA8AZwCxJ38he/jXw/Yj4s1YDRZ0P9JBKK/FcDLOOaTZYjJECxiOSHpL0n3VW0asqIh4kBYxHJd0KfIdCk1ZH1BpSOTbmIZXTjR8czDqqqQ7uiHhGJz4s68zeBBwPvCIi7ujEdctUW8faTVCDo1dDWT0Xw6yjGq3BfVBE/ErSC6u9HhE3tPRh0jzgUuDdEbGppZJWcG6oIdSPOTCeZ2FWpltrcJ8FLAX+tsprAbyslQ+LiC2SXhMRj7byPuuRbt5Y+zWU1eulm3VEo2VVl2Y/j+nUBzpQDKhuP/V7DozZUOv6DG4bMNWWIu3VzPdiwMg5UJgNhZ4lErQBUK/20Iun/lpDWR0wzAbe9KlZVHuiHlTdKGuj2gN096nfQ1nNhlpTwULST5o5NrCGKaFct8panHOyZk2a1ZzfuPMg0eoEtlaCmufAmA23iKi5kdJ07A78HJiX/b47KaHgr+q9t9vbyMhINGViImJsLLXMj41V3x8UvSjrxETeS5G2iYn2PnflyvLX8vesXNn48+vtm1lXAeujjXtuo2AxBvwr8Fj2M99+Dixr5wM7tTUdLCLSDWl0tPwmOTo6mDeq4o0635oJFM3chOtdu5Wb/zAFYDMr05Vg8dRJsLydi3dzaylYrFxZPVg0egqejGo372afqqs9/dfTzI2+0Q1++/byMua/1ytjO0HNzPqq3WBRdzSUpJdFxE+BOyX9SZUmrG9Puh2s2yJgyxZYu7b8+Nq1MDrandXVqo06OuKI9No11+w4EmnlytL1I2DFivLr1RsxFE1OdquX/mLjRjjrLJgzB7Ztg1WryverzbXI31/M7utRTWZTV71IAoxnP79QZft8O9GpU1tLfRaVtYp6TVHttsUXP6/yCb74+fln5ucsXlw6Vjx38eLmm3daecqvPLZ9e+m9CxdW/1ntWq5ZmA0lutVnkf08qp2Ld3PrSjNUp9riq91IR0erlyE/ll9/8eLyoNJKx3ErTVeNylsvALjPwmxodStYbMx+3tDOxbu5da2Du1NPzLVGHdUbiVSrbM10bk+2zJVlaxR0JlsDM7O+6Faw+AZwG/A7YFNhuwnY1M4Hdmrr6tDZWjf1ZjVbs8g/v1O1gnaf8lutWRTfV2/fzAZOu8GiUSLBt0jaG/gRac3s4dPqugZR6IzO5R3O8+Y1nhwXUd7BvHp1en/ewT46ChdcUDonBeVyraTAmOy6DcXyLlyYOruLP4sd540yuLpz22zKamoNbgBJs4ADst1bI+KJrpWqCU+tZxFNjlSqPK/a+yJ2vLHDjjf6Rp/X7GioFStg3bq0jY2VRiHlgWbVqvL1oyf79zUqbyujocxsKLW7nkVTwULSEuDLwL8BAvYFTo6IK1v9wE5ZtGhRrL/++s4vnjM+nobaQvlw28WLSzf6ZlS7ecOOxz784cG4UeflrfXTzKaEdoNFcx0bsAE4sLB/ALChnXavTm0jIyOdHYFT2aG8fXv9foROttcXh6/mE+Qm+7cNan/CoJbLbJqgzT6LZrPO7hQRtxYCzK+BnVqOTJ20YUN5v8Bknn7z5H0TE2l/YgJGRsrPKSbV63SyvxkzypP8zZw5ub9tUBMnDmq5zKyhZoPFBkl/J+nobPssMBgLYFem1W5VRGkG9MgInHMO7L136uCdPx8+9KFSR28eULqxUFCzCwNVXr/afi8WMmrVoJbLzJrTTPUD2Jm0Hve3s+1MYOd2qjKd2kYqh6ROZnz/2WdHzJ9f3uw0c2b6WZzNfM456fxm5zW00uTSzDWbndswqLOrB7VcZtMI3UokCMykz+nIq20jCxZUT6PRqnpzDIo3tO3bd3xfrT6NbmRxbXU+xWTmbnTToJbLbJroWrBI1+Y7wH7tfECda76GLJ1IO9tI8YaT51Fq1/btpRpEM7OY6826zmeL52k7Ork+RCs1mkF8gh/UcplNI90OFlcC/wn8BLgs39r5wOx6xwIbgVe0e42RRk+nzTYBNVuzqLyJF5vAKpvEqr1WWUuoVrZmytzoyXxQ8zYNarnMppl2g0XdGdwFZ0+uZ6RE0pHAV4DXRMR1kuYAc4H7I+K/Grx3KbAUYL/iC5UznqtNiqs1H0NKcxrmz4cHHigdnz0bHn20+izm4ozp3Nq1pXkZxdeKczVWry7Nq2i2bEX5ufX+9snO6O6WQS2XmTWnXiQhLau6ArgIOAN4WjsRqeKaBwJ3ACcCewCXA98HLgXeSDZRsNE2smBB59r2iym6zzmnvFP77LNrdyIXfy8+7ecLCVVrqlq+vL2n63b+rnr7/TKo5TKbJuhSIsFLgK9mgeKfgDXtfEiV6x4G/CYLGu8kDeE9jZS4cPdmrvFUIsHKtv1amVzr3Yzz/oK8EzufFFcc/VRLtc867LBSUJg/P+JFLyr1YSxcGHH44c2VrfLYOec406uZTUq7waJuug9JN0XEH2W/Pw24LiJe2IkajaSDgZdFxEWFYz8E3hcRGxu9/6ncUJBuuVJ58xOU51WamKjf1JFfo9Z+rffkcwVGR9NnXJT9OQsWpP28aWvZMviXf0nzN0ZHy5unimWr9rcUm6vmzElNWa2U08ws0266j0aT8p5KFhgRT7Zcqjoi4paKQPEGYE/g7pYvlt9M80lfK1bsuDTpihXpnHrXqLefCr3jsbwdfu7cFJyWLUvH77uvvA/kootKgaJSXrY8IKxcWXsC27Zt5eVoddKemVkbGnVwHybpoex3Abtk+wIiInabbAEkCTgVeA/wpoi4t+WL5E/Xq1en34tP7cXMsfk57TyJ1+s0z5P/5et6N1I8r9gxnu/nGWchBYi8g71R+o9WOvbNzFrRTttVJzdS4DkaOKiV99Xts6gcWtpK2361DthmJ83VWuu7ck5ItTW3aw3TbXYCm4emmlkT6OY8i0HcdhgNNTpanq210dyGaupNjGvUaT4xUerUrrYddlj5HIxGAaGdCWye9GZmDUy/YFH5tL58efnNePny8lnUlek6KjVbe6h1Y5+YKH1ete2cc6rXgqrd3KulKG9liG2ztREzm3baDRbNTsobbIsXp7b+xYtTX8C118J118Hy5enYnDmpT2Hu3NR5XK3NvzhJrFo/AVSfEDdnTuongLTi3fLl6fe//3u4557Sudu2pZ+V/QnFVOT5PqTrtjqBLb9mZRknm8LdzKydCDMIW1nNolpqjbzGsWzZjjWOynxLRdUWPapX68gn8OV9EcWmqHySX61aQaN8UK1MYHOfhZk1gWlXs1iwID25F+c5FOVzGdatS/uLF6db+IUXpt9Xrtwx9UatRY9Wr66dqmLOHFiyJJWh+FmLF6dzZswoDV+trBWMj5fPk6gcrdXMcN7ia06nYWbd0k6EGYStbDRUsX+i2KFcq/+gsjM87ycopvmo1m9QLwFgtdpItXO7zek0zKwOurys6uCKgKuuSk/1Y2OwfTscdhj8/OfVzx8dhQsuqL6U6caNKXHghg3lr+dP5tWe9KNGP0GlXj3Zt1IbMTNr0vAGi82b0436rLNKN/lVq9LNccmS2u/Lm4Sg+lKmeaAovl5rQlseKPJO6omJUvAprjVtZjbkhrfP4r77Sjf1fMZz3j+Q9x1Uc+GF6Wc+6qiyFnDWWaVrgfsJzMygfiLBQbZIivX5Tp6Ir/ikv3x5ChrXXZfOWbYsnXPhhbD33rB0aRrOumZNqenprLNK+699bXnCvnqKndTV9s3MBkS3EgkOh7zJp/ikv2YNHHdc6r8AuP761FexcGEaRbVtG+y2W9rfuLFUo8j3KxP21eN+AjOb6trpFR+ErWq6j3zkT3G29vbt9fMv1UsRYmY2xdCN9SwG2aK99or199yTOp8vuwxmzYLjj0/zJ1asgHnzSvMYItJop9z27aX+jbz5qpW1L8zMhlS7zVDD3cG9YkXql9iYrZX04henY3nqjwj40Y/SWtpF++wDZ5yRmprmzCml4sg5RYaZWZnhDRYLFpSvAwHl+4cfnmZn5yOj9tgDHnww/X7vvfDJT6b9vI+iWn4mBwwzM2CYg8W++6baRTX5xDtIwWLdulKgyD34YAoQebqOfI5GMY2HA4WZGTDMo6E2b258jgTXXFP79dWr0/DY3XZLo6HyPoxVq1LTlFeXMzMDhjlY3HdfqkFUW8Z07drUdzExseNa3EVnnpk6u7/73fJZ1/l8i61bPQvbzIxhnpS3116x/u674cgjUzPTYYfBiSfCli1p4t3hh6cO77wfozJfVN6HkfdZ5D9zjda7Bk/GM7OhM/0m5e27bxruetxxqXZxww3pRn3ddXDooen43LlptvaCBakPYnQ0zezea69SH0beub1hQ/n1GwWK8fHy/E/57HE3XZnZFDS8wSI3Pp46s6VUq1i3DjZtSr9v3Zpma993X6pZ5Pma7ryz/Br5SnpF9RIBRqRrF5uu8lFUbroys6monZl8g7A9tZ5FbmIi4sknq6+Yt3x5+ZoX+boV+TZ/fvnM7WZWmKu1frZnfpvZAGPazuDOZ2Dvu2/qrN68GXbaqfzkfNW85cvhyivL+y7yvor581MtZObM0op5c+bAFVfULoRnfpvZkJl+fRb33VdqAhobS01L99wDz3zmjueuXVuae7HzzuWvrV+fAsYDD8C7373jGhnFPomivOmpyGtYmNlU1U51ZBC2kQULypuAli0rNSdV25YtS01RlcfHxlLzVWWTUr60akSpyWnlyvL9VpuuGvGSqGbWZUy7ZVWLiQEhdS7PmlX7/IsuKi18NDpavqrdu9+dJuIV5WnL8xpEsfO61qJHxSVYW+XRVWY2wIY33cfWreX7L3gB3HVX+bHZs3dMIpg3R1Wm9qgcDbVwYQoQeZ6oynkXeUbbfD+/XjuBIgqjq6A8R9XYmOdvmFnf9aVmIelASUdI2knSzMbvqOKRR9INPbdpU/o5f37p2KOPpoBRuyCl1B6V62gXJ+hB9UDQqUWPijWTNWtSp3leHiczNLMB0PNgIelPgO8A/wv4HPCXknZr+UILFuw4kW6vvVInd9Gjj6ab7vbt6efateXNPTNm7NiklK+YV9TtzutiTSfnQGFmA6KnwULSTsBJwOkR8XJS0NgXeG8zAUPSUknrJa2/f/bsHZuO3vSm6s1Jq1aloFCrX2F8vHRjLo6GKtY0ihPwusGjq8xskLXTK97uBuwE/AA4JdufASwBPgb8OVmuqma2p0ZD5aOPipPx8iVWq41QamaE0cqVO76nOBqq07o1usrMrALDMilP0iuA5cDHI+KqrM/iJOAE4O3RZIEW7bNPrH/Tm0qd1REpcWCeljw/duaZqSbR6qiiyk7lbncyj4+nTu5iDafdspuZ1TBMy6peBRwIvF2SIuJK4OuS/gw4DNhY9931vPjF5U1Mkxmh1KnO62Z1cnSVmVmH9TxYRMSjkr4GBPB+SQcBjwF7AXc3faHt21NndX5TPfPMtF851HSYbra9DlBmZk3qW24oSbOAlwBnAI8CayLixmbfv2jRolh/1FGluQmQAkXemW1mZjsYpmYoACLiceBySVem3Zho+SJz5pTvr1qVRjK5nd/MrKP6/ggeEdvbChQAl11Wvj8y0v6aEpXne8iqmdlT+h4s2rZ5cykzbC7fX7WqtfZ+52UyM6treIPFzJnVl0N97Wtb67Mo5mXyqndmZlUNbyLBffYp9VEUbdvW2pyIYpqNeokDzcymseGtWUAKFJUJANtJy+G8TGZmdQ13sOjUmhLOy2RmVtfwNkNBZ2Y9F/so8sCT74NrGGZmDHuwgMnPeq616h20v+qdmdkU07cZ3JO1aNGiWL9+fecu2OvEgWZmfdDuDO7h7rOAzvUrOC+TmVlNwx0sPHnOzKwnhjtYePKcmVlPDG8H94YNaVpHkGgAAAvVSURBVPPkOTOzrhveDm4p1kOajOdAYWbWlOnbwe3Jc2ZmXTe8zVAjI1Bc/MhNUWZmXTO8wQI8ec7MrEeGO1i0k97DzMxaNvx9Fg4UZmZdN/zBwszMus7BwszMGnKwMDOzhhwszMysIQcLMzNryMHCzMwacrAwM7OGHCzMzKwhBwszM2vIwcLMzBrqS7CQ9GxJe/bjs83MrHU9TyQo6QTgg8Bb2njvUmBptvuYpJs7WbZpbD7wQL8LMYX4++wsf5+ddWA7b+rpSnmSXglcAJwWEddIUhQKULnf4Frr21ntyXbk77Kz/H12lr/Pzmr3++xZzULSXOAU4JosUMwFlkt6CHggIr7WbKAwM7Pe6lmfRURsBb4C3C3pPOBnwDOAWcBY1sRkZmYDqCc1i7x5KSK+L2kCOB34VERclL1+J3BQi5e9uNPlnMb8XXaWv8/O8vfZWW19nz3rs5C0U0Q8kf0+EhEbCq+9D3g28OduijIzGzw9aYaSNKMQKD4M7F947W3AScAFDhRmZoOp68EiCxQT2e8fA5YA38n2FwFvB94WEb/sdlnMzKw9XW2GqggUnwAOAV4TEU8WzpkXEVu6VggzMwNam55Qqas1i0Kg+FvgYLJAIWmmJGXnNBUoJL1G0lj3Smv5fxNrn6Rd+l2GqULSvpJmSdo123d6okmQtBg4st3396IZaj/SjMHX5oEiIra3Et0kHQucC9zSrXJOR5IWS1oi6UUAEREOGO3LJp0ukzS732UZdpJeBfwAuAj4gqQDI2LCAaM92f+bXwIebfsavehTzqs+eaBo8b1HAv9IqpVcJ2kOMBe4PyL+qxvlnQ4kHQ+sBS4H9gR+GxGnZ6+1XVWdrrLv83xgLCKuqHjN32eTsoeV3we+DywHfknq13w38McR8Yti87Y1Juko4BJS3/Dlkn4vIh6WtEtEPNLs99mTeRb5P5RWA0XmQeAJ4JmS9gC+BTwCPCzpUuAf/A+xNZJmAicDH4mIr0jaDfiBpG9FxBvzGoa/1+ZIOhj4FHBeRFyR/X86H5gVETf5+2xe9l3dBVwD3AbcFxGfkPQE8GNJx0TEr/tbyqFzKHA18KCkZwHnZZkz9pD0gYi4rZn/Pwe+ShcRtwKvAlYDPwe+Drwa+CHwBmBe/0o3nLKgfWNh/6GIeAmwl6T/nR3zja15u5CaTCYkHUd6ivsIsErSheDvsxmSnps1ic4F5gBvLTxorgHWAB+QNNvNpY1l3+fBwLdJGTPeRQoa1wKfB24ALpL0jGb+/xz4YAEQET8nBYjzI+KzETEREZ8nBYr9+lu64SHpgMLuncB7sz6l3OtJTxuH9LZkwyn/PrMJpl8jjfb7JKn2+2bgNOD5kl7at0IOCUmvJt3UPgF8mPR9/oWk9xdOuxR4DHjMwbe+wvf5GVJ/7/WkPt+PRMTaiLiOlH7pTtJ32tBQBAuAiLglTw8CIOkNpLb2u/tXquGR/c+zUdI3ASLiq6S+oKvzgBERDwBPArv2raBDosr3eTXwDeA9EfGZLL3NZuAOUjOq1ZD1S34cODkilpDyxR1OGrnzLkkfkvRc4GhghFTzsBoqvs//DmwH3hwRF5I6uXNLgOcAT2/mukMTLHJKTiNFy3dExL39LtOgy4YeLgNWAI9K+gZARJwNfBH4rqQzJH2Q1L55f7/KOgyqfJ9fB8ie1n5YOO8NpNqGH2ga+2hE5E2jHwReEBF3kQLEc4CzSB3ep3peVlOK3+fZwLMkzYqIxwAknQ78FfCXWZLXhnq6nkUnZG2VS4B7IuJX/S7PsJC0D/AQMJtUNX0iIt6SvfZ6YG/SU9sFEeFFpRqo8n0+FhFvLbx+MimgnOrvs75swMWuEfFQ9vszge8CJ0TE3Vmn7J3ZOdv6WdZhUOf7PDYi7pf0HNL/mxe3cg8dumBhk5eN1rkYeDwi3pL1UTwcEf/e56INpcL3+UhEvE3S84FjgB9GxG/6W7rhIulppAD8nYh4uVLuuJcCKyLikf6WbvjU+D7/CPjriHiopWs5WExPkuaT2jWPBGYCR0fEHf0t1fCq+D4FLIkINz+1SdIXSc13xwKnRMRN/S3RcKv4Pk+NiE2tXqPna3DbYIiIByRtAo4HXuFAMTlVvk8HijZkzcw7kWoTOwEvj4jb+luq4dXJ79PBYpqSNA84gdSO6ae2SfL32RnZkNjHJZ0LXO9AMTmd/D7dDDWNSZodEW3nirFy/j47xzPeO6sT36eDhZmZNTR08yzMzKz3HCzMzKwhBwszM2vIwcLMzBpysLBJk7Rd0kZJN0v6e0lNJSZr4fpXSFrU4JwVxc+V9H1JXUs4J2lPSesk3ViZVVbSTpLOl3SbpBskXaO0ONJT5cq2v2jxM/eR9K0W37NM0u2SIps4mB+XpLXZa5skvbDG+4+TdGt23vsKx5+d/f23S7pE0qzs+M7Z/u3Z6/u3Ul4bXA4W1gmPRMTCiPhD4HHgz/tQhhUUsmdGxAnNJkhr08uBmyLiBRFxVcVr55Ly8fxhRLwQeB3wjIpyzQVaChYRcVdEvLHFcl4N/DFQmcrleOB52bYU+HTlG7O8Qp/Mzj0YeIvS+ggAHwVWR8RzgS3A6dnx04Et2fHV2Xk2BThYWKddBTxX0u6S/il7ar1W0qEAksYlfSV72r5N0juz40dL+l5+EUkXSTql8uKSPi1pvaRfSPpwdmwU2Ae4XNLl2bF/y5+kJZ2V1XpulrQiO7a/pF9K+mx2rR9L2qXK5+0v6afZ3/ETSftJWgh8DDgxq1HtUjj/6cA7geV5hs+IuDciLq0o1/nAH2Tv/7ikL0t6XeE6X5N0YpWy3Jz9foqkb0v6YfY9fqzaf4yIuDEi/q3KSycCX85SqV8LzJX0zIpzDgduj4jfRMTjwDezv1nAy0jrdkBKe/26wnXzNNjfAl6enW9DzsHCOkYpadnxwE2kBWxujIhDgQ8AXy6ceijpZnMEcI5SBtdmfTAiFmXXWCLp0IhYC9wFHBMRx1SUaQQ4FVgMvBh4p6QXZC8/D/hkRBwCbCWtvFjpQuBL2d/xNWBtRGwEzgEuyWpUxQR3zwX+o4kkbe8D/l/2/v8JfA44JSvzHFKOqX9ucI2FwEmkxHAnSdq3wflF/w3YXNi/IzvWzDl7AFsj4skq733qPdnr27Lzbcg5WFgn7CJpI7Ae+A/Sje8o0kpcRMRPSSvw7Zad/52IeCRbbOly0hNss/6HpBtIy8IeQmoeqeco4B8j4ncR8TBp9bC8j+Ffsxs/wAZg/yrvP4K0lC/Z33NUC2VtWkT8X+B5kvYE3kJaW/7JBm/7SURsy2aN3wI8qxtlMwPnhrLOeCQiFhYPNGh5qEwbEKQV+ooPL7Mr3yTp2cB7gBdFxBalTJo7nNeC4nKS20lraU/W7cB+knZrNQU0qfb1NtKSrKc2cX5l+Vv593wnUKyJ/H52rJlzHiQ1Wz0tC2jF9+bvuSOrac7Jzrch55qFdctVwFsh9UcADxRunidKmq20DsTRpPWB/x04OBtNM5fUgVxpN+B3wDZJe5GavHL/SdaJXKUcr5P0dKUV7l6fHWvWz0g3b7K/p+57I+K/SDWrNYURQntKelPFqdXK+0VSRz0RcUsLZWzHZcA7slFRLwa25ZlyJeUL4lxPqu08O/tb3gxcluUYuhzIO9tPBr5TuO7J2e9vBH7qHE9Tg4OFdcs4MKKUtvt8SjcQgE2km821wLnZKJ/NwKXAzdnPG6kQET/Pjv+K1DR0deHli4Ef5h3chffcQLoJXwesA/6usNxkM5YDp2Z/x9uBsSbe8yHS0rS3ZB3S3yOtqlcs14Ok9c9vlvTx7Ni9wC+BL7RQvrokjUq6g/T0v0nS32UvfR/4Dakm9FmykVlZ57uy8jxJWlHtR1m5Lo2IX2Tvfy9wlqTbSX0Sn8uOf47U5Hg7aSnUp4bb2nBzIkHrKUnjpFX5PtHvsgyabCTVTcAL+7V8qKRXA8/JBg2YPcV9FmYDQNIfk57KV/dznemI+F7js2w6cs3CzMwacp+FmZk15GBhZmYNOViYmVlDDhZmZtaQg4WZmTX0/wG8WCLQzHmFAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"El tamaño de X es: \", X.shape[0], \" filas y \", X.shape[1], \" columna(s) \", X.shape)\n",
    "print(\"La longitud del vector y es: \", len(y), y.shape)\n",
    "\n",
    "print(\"Las 5 primeras filas de los datos son: [atributo entrada X1 | clase y]\")\n",
    "for i in range(0,5):\n",
    "  print(\"\\t\", X['poblacion'][i],  \" | \", y['beneficio'][i]) \n",
    "# Recordar: X[:5] selecciona las 5 primeras filas de X.\n",
    "\n",
    "plotData(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5PDJ42J5FuwJ"
   },
   "source": [
    "### 2) Hipótesis y función coste\n",
    "La hipótesis del modelo de regresión lineal univariable es: \n",
    "\\begin{equation}\n",
    "h_{\\theta}(x)=\\theta_0 + \\theta_1 \\cdot x \\quad \\mbox{ ó  } \\quad h_{\\theta}(x)=\\theta^T \\cdot x\n",
    "\\end{equation}\n",
    "Si queremos representar $X$ como la matriz/dataframe con todos los datos de entrada, la hipótesis es equivalente a: \n",
    "\\begin{equation}\n",
    "h_{\\theta}=X \\cdot \\theta\n",
    "\\end{equation}\n",
    "donde: \n",
    "*  $X$ contiene todas las filas y atributos del conjunto de training (sin incluir la clase).\n",
    "*  $\\theta$ es un vector columna de longitud: el número de atributos del conjunto de training (sin incluir la clase) + 1 ($\\theta_0$ ).\n",
    "\n",
    "El objetivo de la regresión lineal es minimizar el coste de la función. Si la función coste es el error cuadrático:\n",
    "\\begin{equation}\n",
    "J(\\theta)=\\frac{1}{2 \\cdot m}\\sum_{i=1}^{m} (h_{\\theta}-y)^2 = \\frac{1}{2 \\cdot m}\\sum (X \\cdot \\theta-y)^2\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT2k42QsHdjH"
   },
   "outputs": [],
   "source": [
    "def computeCost(X, y, theta):\n",
    "\n",
    "    m = len(y) # Numero de instancias en el training\n",
    "    h = np.dot(X, theta) # Hipótesis del modelo de regresión lineal \n",
    "    J = ((np.sum(np.power((h - y),2)))/(2*m)) # Coste\n",
    "  \n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8OEMxo7HcjM"
   },
   "source": [
    "#### 2.1) Añadir $x_0$\n",
    "x0 se añade como primera columna a X con todos sus elementos a 1. Esta operación se realiza para poder calcular la hipótesis h que viene dada por el modelo lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtX1CLX9FiEN"
   },
   "outputs": [],
   "source": [
    "ones = np.ones((len(y), 1)) # Crear un array de 1\n",
    "X['uno'] = ones # Añadir a X # Es lo mismo que X['uno'] = 1\n",
    "X = X[['uno', 'poblacion']]  # Poner 'uno' como primera columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VA6Oo9qVJw6S"
   },
   "source": [
    "#### 2.2) Inicializar $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sszlM4QCHTvh"
   },
   "outputs": [],
   "source": [
    "num_atributos = X.shape[1] # Si esta operación la hacemos antes de añadir la columna de 1 a X, debemos poner X.shape[1]+1\n",
    "theta = np.zeros((num_atributos,1), dtype=np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EiuNxpcgKuW0"
   },
   "source": [
    "Ejecutamos la función coste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJsEtuotKVX7",
    "outputId": "fc512ae2-7d7c-4c76-c0a3-78427e59e716"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El coste inicializando theta a 0 debe ser aproximadamente 32.072734:  beneficio    32.072734\n",
      "dtype: float64\n",
      "\n",
      "El coste probando con theta0=-1 y theta1=2 es:  beneficio    54.242455\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "J_base = computeCost(X, y, theta)\n",
    "print(\"\\nEl coste inicializando theta a 0 debe ser aproximadamente 32.072734: \", J_base)\n",
    "\n",
    "# Si queremos probar con otros valores de theta: \n",
    "J_prueba = computeCost(X, y, [[-1], [2]]) # Lo mismo que: computeCost(X, y, np.array([[-1],[2]]))\n",
    "print(\"\\nEl coste probando con theta0=-1 y theta1=2 es: \", J_prueba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-W9O5P-HLQcN"
   },
   "source": [
    "### 3) Descenso del Gradiente\n",
    "El método de descenso del gradiente se implementa en una función que recibe como parámetro, además de los datos X e y, los parámetros theta, alpha y el número de iteraciones. Estos dos últimos se pueden inicializar a 0.01 y 1500 respectivamente. Si la función coste es el error cuadrático, en cada iteración del descenso del gradiente se calcula:  \n",
    "\\begin{equation}\n",
    "\\theta=\\theta - \\alpha \\frac{1}{m} (X^T \\cdot (X \\cdot \\theta - y))\n",
    "\\end{equation}\n",
    "\n",
    "La función deberá devolver los parámetros theta finales y un histórico con el coste en cada iteración que se debe visualizar. Mostrar por pantalla los valores de theta finales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzGcX-WdKD5y"
   },
   "outputs": [],
   "source": [
    "def gradientDescent(X, y, theta, alpha, iterations):\n",
    "\n",
    "    m = len(y) # Numero de instancias en el training\n",
    "    current_iter = [] # Lista vacía para crear el histórico en un dataframe\n",
    "    current_cost = [] # Lista vacía para crear el histórico en un dataframe\n",
    "\n",
    "    for iter in range(iterations):\n",
    "        h = np.dot(X,theta) # Hipótesis\n",
    "        theta = theta - alpha*(1/m)*(np.dot(X.T,(h-y)))\n",
    "\n",
    "        # Guardar el coste J de cada iteración\n",
    "        current_iter.append(iter) # Añadir la iteración a una lista\n",
    "        current_cost.append(computeCost(X, y, theta)) # Añadir el coste a una lista\n",
    "\n",
    "    J_history = pd.DataFrame({'iteracion': current_iter, 'coste': current_cost}) # Crear el dataframe histórico iteracion-coste\n",
    "\n",
    "    return theta, J_history # Último theta encontrado y dataframe histórico J_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l7cNI-ANj9B"
   },
   "source": [
    "#### 3.1) Visualizar el histórico coste-iteración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PUt5oSIJNUQo"
   },
   "outputs": [],
   "source": [
    "def plotIterationsVsCost(J_history, alpha, iteraciones):\n",
    "    plt.plot(J_history['iteracion'], J_history['coste'])\n",
    "    plt.xlabel('Iteraciones')\n",
    "    plt.ylabel('Coste')\n",
    "    plt.title('Descenso del gradiente con alpha: '+str(alpha)+' y '+str(iteraciones)+' iteraciones')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t0smHhzhzNfv"
   },
   "source": [
    "#### 3.2) Visualizar el óptimo encontrado para el modelo con curvas de nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RrFY0hjs1ET1"
   },
   "outputs": [],
   "source": [
    "def plotData_cost(X, y, theta):\n",
    "\n",
    "    # Grid sobre el que vamos a calcular J\n",
    "    theta0_vals = np.linspace(-10, 10, 100)\n",
    "    theta1_vals = np.linspace(-1, 4, 100)\n",
    "\n",
    "    # Inicializar J_vals a una matriz de ceros\n",
    "    J_vals = np.zeros((len(theta0_vals), len(theta1_vals)))\n",
    "\n",
    "    # Rellenar J_vals\n",
    "    for i in range(1, len(theta0_vals)):\n",
    "        for j in range(1, len(theta1_vals)):\n",
    "            theta_ij = [[theta0_vals[i]], [theta1_vals[j]]]\n",
    "            J_vals[i][j] = computeCost(X, y, theta_ij)\n",
    "\n",
    "    # Debido a la forma en la que las mallas funcionan en el comando contour, \n",
    "    # debemos transponer J_vals antes de llamar a dicha función\n",
    "    J_vals = J_vals.T\n",
    "\n",
    "    fig1, ax = plt.subplots(1,1)\n",
    "    contour = ax.contour(theta0_vals, theta1_vals, J_vals, np.logspace(-2, 3, 20))\n",
    "    fig1.colorbar(contour)\n",
    "    plt.xlabel(\"theta_0\")\n",
    "    plt.ylabel(\"theta_1\")\n",
    "    plt.plot(theta[0], theta[1], marker = 'x', c='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fX1myh4QzRyd"
   },
   "source": [
    "#### 3.3) Visualizar gráficamente el modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUpOzmur2CKT"
   },
   "outputs": [],
   "source": [
    "def plotData_linearRegression(X, y, theta):\n",
    "    plt.scatter(X['poblacion'],y, marker=\"x\", c=\"red\", label=\"Training data\") # Representación del conjunto de datos\n",
    "    plt.plot(X['poblacion'], np.dot(X, theta), c='blue', label=\"Linear regression\") # Representación de la recta: h = X·theta\n",
    "    plt.xlabel(\"Population of City in 10,000\")\n",
    "    plt.ylabel(\"Profit in $10,000\")\n",
    "    plt.xlim(5, 25) # Cuidado: estamos limitando el eje X \n",
    "    plt.ylim(-5, 25) # Cuidado: estamos limitando el eje y\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRoJoUi5OE2C"
   },
   "source": [
    "## B) EJERCICIO DE EVALUACIÓN USANDO HOLDOUT\n",
    "Se divide el dataset en 70% para entrenamiento y 30% para test usando una de las funciones holdout suministradas. La función deberá devolver: X_training, y_training, X_test e y_test.\n",
    "Después, obtener el modelo de regresión lineal usando el descenso del gradiente con el conjunto de entrenamiento (training) para alpha=0.01 y 1500 iteraciones. Visualizar la función coste J a través de las iteraciones. Visualizar el modelo obtenido (si es regresión lineal univariable).\n",
    "Por último, predecir el conjunto de test y calcular el error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vesiK2BMxfr9"
   },
   "source": [
    "### 1) Cargar los datos de entrada diviendo el dataset en 70-30 mediante holdout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LB9Mf1JHQMt8"
   },
   "outputs": [],
   "source": [
    "# OPCION 1\n",
    "def holdout_opcion1(X, y, percentage=0.6):\n",
    "  index_training = [] # Lista vacía con los indices del training\n",
    "  while len(index_training) < round(percentage*len(X)): # Mientras el número de elementos en la lista de índices del training sea menor del que debe ser:\n",
    "    random_index = randrange(len(X)) # indices random dentro del rango de X\n",
    "    if random_index not in index_training: # si el indice random no esta en la lista de indices del training\n",
    "      index_training.append(random_index) # Añado el indice random a los indices que formarán parte del training\n",
    "\n",
    "  # Una vez tenemos en index_training los índices que formaran parte del conjunto de training:\n",
    "  X_training = X.iloc[index_training]\n",
    "  y_training = y.iloc[index_training]\n",
    "  X_test = X.iloc[~X.index.isin(index_training)] # ~ significa NOT\n",
    "  y_test = y.iloc[~y.index.isin(index_training)] # ~ significa NOT\n",
    "  print(\"El tamaño del training debe ser: \", round(percentage*len(X)), \" - Comprobación: tamaño X_training es \", len(X_training), \" y tamaño y_training es\", len(y_training))\n",
    "  print(\"El tamaño del test debe ser: \", len(X)-round(percentage*len(X)), \" - Comprobación: tamaño X_test es \", len(X_test), \" y tamaño y_test es\", len(y_test))\n",
    "  \n",
    "  # Reseteamos los índices de todos los conjuntos\n",
    "  X_training = X_training.reset_index(drop=True)\n",
    "  y_training = y_training.reset_index(drop=True)\n",
    "  X_test = X_test.reset_index(drop=True)\n",
    "  y_test = y_test.reset_index(drop=True)\n",
    "  \n",
    "  return X_training, y_training, X_test, y_test\n",
    "\n",
    "# OPCION 2\n",
    "def holdout_opcion2(X, y, percentage=0.6):\n",
    "  X_training = X.sample(round(percentage*len(X))) # Selecciona aleatoriamente el numero de filas indicado\n",
    "  y_training = y.iloc[X_training.index] # Selecciona las filas del X_training\n",
    "  X_test = X.iloc[~X.index.isin(X_training.index)] # ~ significa NOT\n",
    "  y_test = y.iloc[~X.index.isin(X_training.index)] # ~ significa NOT\n",
    "\n",
    "  print(\"El tamaño del training debe ser: \", round(percentage*len(X)), \" - Comprobación: tamaño X_training es \", len(X_training), \" y tamaño y_training es\", len(y_training))\n",
    "  print(\"El tamaño del test debe ser: \", len(X)-round(percentage*len(X)), \" - Comprobación: tamaño X_test es \", len(X_test), \" y tamaño y_test es\", len(y_test))\n",
    "\n",
    "  # Reseteamos los índices de todos los conjuntos\n",
    "  X_training = X_training.reset_index(drop=True)\n",
    "  y_training = y_training.reset_index(drop=True)\n",
    "  X_test = X_test.reset_index(drop=True)\n",
    "  y_test = y_test.reset_index(drop=True)\n",
    "  \n",
    "  return X_training, y_training, X_test, y_test\n",
    "\n",
    "# OPCION 3\n",
    "def holdout_opcion3(X, y, percentage=0.6):\n",
    "  X_training, X_test, y_training, y_test = train_test_split(X,y, test_size=1-percentage, random_state=1) # Cuidado con el orden de la salida\n",
    "  # random_state: controla el barajado aplicado a los datos antes de aplicar la división. Si le pasamos un int, la salida se reproducirá siempre que llamemos a la función\n",
    "  \n",
    "  print(\"El tamaño del training debe ser: \", round(percentage*len(X)), \" - Comprobación: tamaño X_training es \", len(X_training), \" y tamaño y_training es\", len(y_training))\n",
    "  print(\"El tamaño del test debe ser: \", len(X)-round(percentage*len(X)), \" - Comprobación: tamaño X_test es \", len(X_test), \" y tamaño y_test es\", len(y_test))\n",
    "  \n",
    "  # Reseteamos los índices de todos los conjuntos\n",
    "  X_training = X_training.reset_index(drop=True)\n",
    "  y_training = y_training.reset_index(drop=True)\n",
    "  X_test = X_test.reset_index(drop=True)\n",
    "  y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "  return X_training, y_training, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nP-iWpPwQVUs",
    "outputId": "ad5564c6-194b-4cff-a30d-cc7f3aba3b84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El tamaño del training debe ser:  68  - Comprobación: tamaño X_training es  68  y tamaño y_training es 68\n",
      "El tamaño del test debe ser:  29  - Comprobación: tamaño X_test es  29  y tamaño y_test es 29\n"
     ]
    }
   ],
   "source": [
    "# Importante: Cargar el dataset X, y si no lo tienes ya cargado.\n",
    "\n",
    "X_training, y_training, X_test, y_test = holdout_opcion1(X, y, 0.7)\n",
    "#X_training, y_training, X_test, y_test = holdout_opcion2(X, y, 0.7)\n",
    "#X_training, y_training, X_test, y_test = holdout_opcion3(X, y, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YrX6VkrzZMy"
   },
   "source": [
    "### 2) Hipótesis y función coste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qsfqYOff0Xw8"
   },
   "source": [
    "#### 2.1) Añadir $x_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lsBvnq60caX"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# Incluir x0 (antes o después de cargar el dataset X, y). \n",
    "# Tanto X_training como X_test deben incluir una columna (será x0) con todos los elementos a 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lC2E2bRj0aqt"
   },
   "source": [
    "#### 2.2) Inicializar $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GSsS787zXoe"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A8W-B-7k0nYh"
   },
   "source": [
    "### 3) Descenso del Gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAKbxvxFDvmL"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR \n",
    "iterations = 1500\n",
    "alpha = 0.01\n",
    "theta_optimo_holdout, J_history_holdout = gradientDescent(....)\n",
    "\n",
    "print('Theta encontrado con el descenso del gradiente: \\n', theta_optimo_holdout)\n",
    "print('\\nCoste alcanzado en la última iteración : ', J_history_holdout[J_history_holdout['iteracion']==iterations-1]['coste']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rzJ_AqZ0_LL"
   },
   "source": [
    "#### 3.1) Visualizar el histórico coste-iteración\n",
    "¿Ha encontrado el óptimo el descenso del gradiente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oni9fv8Y03FV"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR \n",
    "plotIterationsVsCost(....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RG5-qOHe1P0N"
   },
   "source": [
    "#### 3.2) Visualizar el óptimo encontrado para el modelo con curvas de nivel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLds6wVS183j"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "plotData_cost(....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bx53mVm93GtG"
   },
   "source": [
    "#### 3.3) Visualizar gráficamente el modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CCubWsJy3Raj"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR \n",
    "plotData_linearRegression(....)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZUCCSO83Qbr"
   },
   "source": [
    "#### 3.4) Predecir el conjunto de test usando el modelo aprendido con el conjunto de training. Calcular el error MAE y MSE.\n",
    "Las métricas que usaremos están en la EB T2 diap 39: \n",
    "\n",
    "\n",
    "*   Error absoluto medio (MAE): \n",
    "\\begin{equation}\n",
    "MAE =\\frac{1}{m}\\sum_{i=1}^{m} |y_i - \\widehat{y}_i|\n",
    "\\end{equation}\n",
    "*   Error cuadrático medio (MSE): \n",
    "\\begin{equation}\n",
    "MSE =\\frac{1}{m}\\sum_{i=1}^{m} (y_i - \\widehat{y}_i)^2 \n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eQvMNYk73d8C"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# Predicción de todo el conjunto de test\n",
    "y_predicted = ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w10dc8oRE21r"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR\n",
    "# Calcular los errores\n",
    "m = len(y_test)\n",
    "\n",
    "# MAE: \n",
    "error_absoluto_medio_holdout = ....\n",
    "print(\"El error absoluto medio es: \", error_absoluto_medio_holdout)\n",
    "MAE_sklearn_holdout = metrics.mean_absolute_error(y_test, y_predicted)\n",
    "print(\"El error absoluto medio usando sklearn es: \", MAE_sklearn_holdout)\n",
    "\n",
    "# MSE: \n",
    "error_cuadratico_medio_holdout = ....\n",
    "print(\"\\n\\nEl error cuadrático medio es: \", error_cuadratico_medio_holdout)\n",
    "MSE_sklearn_holdout = metrics.mean_squared_error(y_test, y_predicted)\n",
    "print(\"El error cuadrático medio usando sklearn es: \", MSE_sklearn_holdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWxHdmHU-aEH"
   },
   "source": [
    "## C) EJERCICIO DE EVALUACIÓN USANDO CROSS-VALIDATION\n",
    "La evaluación mediante validación cruzada consiste en la división del conjunto de datos en K bolsas, haciendo que cada una de estas bolsas sea el conjunto de test mientras que las K-1 restantes sean el conjunto de entrenamiento. \n",
    "\n",
    "De esta forma, se calculan K modelos y el error que cada uno de ellos comete al predecir el conjunto de test correspondiente. \n",
    "\n",
    "La media de los K errores es el error que determina si la regresión lineal es un buen método de aprendizaje y la predicción de una instancia desconocida se estimaría con la media de la predicción obtenida por cada modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7SDlNmtM16E"
   },
   "source": [
    "#### 1) Cargar los datos de entrada y dividirlo en los conjuntos de entrenamiento y test mediante validación cruzada.\n",
    "Usar una de las siguientes funciones para construir los índices que nos ayudarán a crear las diferentes bolsas en las que se dividirá el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2A6IOhjtJMs"
   },
   "outputs": [],
   "source": [
    "def cross_validation_opcion1(X, y, K):\n",
    "  tam_folds = round(len(X)/K) # Tamaño de cada bolsa considerando que creamos K bolsas\n",
    "  data_particiones = [] # Lista que devolveremos con los índices de cada bolsa\n",
    "  all_bolsa = [] # Lista de indices totales en el que vamos a añadir todos los índices que se van incluyendo en data_particiones para controlar que no se repiten\n",
    "  for i in range(K): # Para cada bolsa\n",
    "    fold = [] # Lista vacío con los indices de la bolsa, deberá tener tamaño tam_folds\n",
    "    while len(fold) < tam_folds:\n",
    "      random_index = randrange(len(X)) # indices random dentro del rango de X\n",
    "      if random_index not in all_bolsa: # si el indice random no esta en la lista de indices totales\n",
    "        fold.append(random_index) # Añado el indice random a los indices que formaran parte de la bolsa\n",
    "        all_bolsa.append(random_index) # Añado el indice random a la lista de indices totales\n",
    "    data_particiones.append(fold) # Cuando fold ya esté correctamente completado, antes de pasar a la siguiente bolsa, se añadirán todos esos índices a la lista que devolveremos\n",
    "  return data_particiones\n",
    "\n",
    "def cross_validation_opcion2(X, y, K):\n",
    "  cv = KFold(n_splits=K, random_state=None, shuffle=True) # random_state como anteriormente, shuffle = True: Se barajan los datos antes de divirlos en lotes\n",
    "  data_particiones_sk = [] # Lista vacía donde añadiremos los índices del test cada bolsa\n",
    "  for train_ix, test_ix in cv.split(X): # cv.split(X) genera índices para dividir los datos en training y test\n",
    "    data_particiones_sk.append(test_ix)\n",
    "  return data_particiones_sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U85Dt970QeXe"
   },
   "outputs": [],
   "source": [
    "K = 5 # Número de particiones para cross-validation\n",
    "\n",
    "indices = cross_validation_opcion1(X,y,K) # indices serán los índices del conjunto de test\n",
    "#indices = cross_validation_opcion2(X,y,K) # indices serán los índices del conjunto de test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0YlGULJli9g1"
   },
   "source": [
    "### 2) Hipótesis y función coste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxSQ6IgEjINb"
   },
   "source": [
    "#### 2.1) Añadir $x_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q0u8EehUGP6Z"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EjjuJhqBjJ51"
   },
   "source": [
    "#### 2.2) Inicializar $\\theta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-y5V7d1jV5s"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ecie7-FjMOF"
   },
   "source": [
    "### 3) Descenso del Gradiente considerando cross-validation\n",
    "Una vez creados los conjuntos, obtener el modelo y el error para cada uno de ellos. Para obtener el modelo, ejecutar el descenos del gradiente llamando a la función correspondiente con el conjunto de entrenamiento correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QqabJ5aQjSLz"
   },
   "outputs": [],
   "source": [
    "iterations = 1500 # Inicialización de alpha y número de iteraciones\n",
    "alpha = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4rIEHmJ-IOsG"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR \n",
    "error_abs = [] # Lista vacía para almacenar los errores de cada conjunto train/test y luego calcular el error medio cometido\n",
    "arr_J_history = [] # Lista vacía para almacenar los J_history de cada conjunto train/test y luego poder visualizar la función coste J a través de las iteraciones de cada modelo\n",
    "arr_theta_optimo = [] # Lista vacía para almacenar los theta optimos de cada conjunto train/test\n",
    "arr_id_bolsa = [] # Lista vacía para almacenar el id de la bolsa con los índices de cada conjunto train/test\n",
    "arr_X_training = [] # Lista vacía para almacenar cada conjunto de training X\n",
    "arr_y_training = [] # Lista vacía para almacenar cada conjunto de training y\n",
    "\n",
    "for i in range(0,K): # Para cada bolsa\n",
    "  print(\"\\nBOLSA: \", i)\n",
    "  # Crear los conjuntos test/training\n",
    "  X_test = ....\n",
    "  y_test = ....\n",
    "  X_training = ....\n",
    "  y_training = ....\n",
    "\n",
    "  #print(\"El tamaño del training debe ser: \",len(X)-round(len(X)/K), \" - Comprobación: tamaño X_training es \", len(X_training), \" y tamaño y_training es\", len(y_training))\n",
    "  #print(\"El tamaño del test debe ser: \", round(len(X)/K), \" - Comprobación: tamaño X_test es \", len(X_test), \" y tamaño y_test es\", len(y_test))\n",
    "\n",
    "  # Reseteamos los índices de todos los conjuntos\n",
    "  X_training = ....\n",
    "  y_training = ....\n",
    "  X_test = ....\n",
    "  y_test = ....\n",
    "\n",
    "\n",
    "  # Descenso del gradiente\n",
    "  theta_optimo_cv, J_history_cv = gradientDescent(.....)\n",
    "  print('\\tTheta encontrado con el descenso del gradiente: \\n', theta_optimo_cv)\n",
    "  print('\\n\\tCoste alcanzado en la última iteración : ', J_history_cv[J_history_cv['iteracion']==iterations-1]['coste']) \n",
    "  arr_theta_optimo.append(....) # Añadir theta_optimo_cv a la lista de theta optimos\n",
    "  arr_J_history.append(....) # Añadir J_history_cv a la lista de J_history\n",
    "  arr_id_bolsa.append(....) # Añadir el id de la bolsa que se está recorriendo a la lista de ids\n",
    "  arr_X_training.append(....) # Añadir el X_training a la lista de X_training\n",
    "  arr_y_training.append(....) # Añadir el y_training a la lista de y_training\n",
    "\n",
    "  # Predicción de todo el conjunto de test\n",
    "  y_predicted = .... \n",
    "\n",
    "  # Errores\n",
    "  MAE_sklearn_cv = metrics.mean_absolute_error(y_test, y_predicted)\n",
    "  print(\"\\tEl error absoluto medio usando sklearn es: \", MAE_sklearn_cv)\n",
    "  MSE_sklearn_cv = metrics.mean_squared_error(y_test, y_predicted)\n",
    "  print(\"\\tEl error cuadrático medio usando sklearn es: \", MSE_sklearn_cv)\n",
    "  error_abs.append(MAE_sklearn_cv) # Añadir MAE a la lista de errores\n",
    "\n",
    "  print(\"--------------\")\n",
    "\n",
    "print(\"\\n\\nFIN\\n\\nError medio usando descenso del gradiente: \", ....)\n",
    "df_cv = .... # Crear dataframe con todo lo necesario para poder realizar las visualizaciones que se nos piden a continuación: ids, thetas optimos, J_history, ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okO8jHPS4BY9"
   },
   "source": [
    "#### 3.1) Visualizar el histórico coste-iteración\n",
    "De cada conjunto training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nBVnEjDX3jjs"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWH5LpMG4Sk7"
   },
   "source": [
    "#### 3.2) Visualizar el óptimo encontrado para el modelo con curvas de nivel\n",
    "De cada conjunto training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZI_bLd-e3s8i"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yppY9k9t5AoO"
   },
   "source": [
    "#### 3.3) Visualizar gráficamente el modelo obtenido\n",
    "De cada conjunto training/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O0GYpnAU4_ee"
   },
   "outputs": [],
   "source": [
    "# COMPLETAR"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
